{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>2 hours 17 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_started_from_R_jay_lkj507</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.402 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         2 hours 17 mins\n",
       "H2O cluster timezone:       Asia/Kolkata\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.2\n",
       "H2O cluster version age:    1 month\n",
       "H2O cluster name:           H2O_started_from_R_jay_lkj507\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.402 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.8 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data = h2o.import_file(\"http://h2o-public-test-data.s3.amazonaws.com/smalldata/airlines/allyears2k_headers.zip\")\n",
    "train, valid, test = data.split_frame([0.8,0.1],seed = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35255/4272/4451\n"
     ]
    }
   ],
   "source": [
    "print(\"%d/%d/%d\" % (train.nrows,valid.nrows,test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"IsArrDelayed\"\n",
    "ignoreFields = [\n",
    "    \"ArrDelay\",\"DepDelay\",\"CarrierDelay\",\n",
    "    \"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\n",
    "    \"LateAircraftDelay\",\"IsDepDelayed\",\"IsArrDelayed\",\"ActualElapsedTime\",\"Arrtime\"] #But CRSElapsedTime is fine.\n",
    "xAll = [i for i in train.names if i not in ignoreFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 1.48 s, sys: 86.8 ms, total: 1.57 s\n",
      "Wall time: 3min 50s\n"
     ]
    }
   ],
   "source": [
    "m_def = H2ODeepLearningEstimator()\n",
    "%time m_def.train(xAll,y,train,validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.09786065422926134\n",
      "RMSE: 0.3128268758103455\n",
      "LogLoss: 0.3074628847256683\n",
      "Mean Per-Class Error: 0.14033740350013835\n",
      "AUC: 0.9408581182911451\n",
      "pr_auc: 0.6937186786278869\n",
      "Gini: 0.8817162365822901\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4622419872528487: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1616.0</td>\n",
       "<td>334.0</td>\n",
       "<td>0.1713</td>\n",
       "<td> (334.0/1950.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>278.0</td>\n",
       "<td>2223.0</td>\n",
       "<td>0.1112</td>\n",
       "<td> (278.0/2501.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1894.0</td>\n",
       "<td>2557.0</td>\n",
       "<td>0.1375</td>\n",
       "<td> (612.0/4451.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1616  334    0.1713   (334.0/1950.0)\n",
       "YES    278   2223   0.1112   (278.0/2501.0)\n",
       "Total  1894  2557   0.1375   (612.0/4451.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4622420</td>\n",
       "<td>0.8790036</td>\n",
       "<td>207.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2073254</td>\n",
       "<td>0.9231409</td>\n",
       "<td>300.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7408131</td>\n",
       "<td>0.8958826</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4640101</td>\n",
       "<td>0.8625028</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999645</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0120101</td>\n",
       "<td>1.0</td>\n",
       "<td>388.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999645</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4640101</td>\n",
       "<td>0.7200913</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5291967</td>\n",
       "<td>0.8584566</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5669876</td>\n",
       "<td>0.8596626</td>\n",
       "<td>170.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.462242     0.879004  207\n",
       "max f2                       0.207325     0.923141  300\n",
       "max f0point5                 0.740813     0.895883  115\n",
       "max accuracy                 0.46401      0.862503  206\n",
       "max precision                0.999964     1         0\n",
       "max recall                   0.0120101    1         388\n",
       "max specificity              0.999964     1         0\n",
       "max absolute_mcc             0.46401      0.720091  206\n",
       "max min_per_class_accuracy   0.529197     0.858457  183\n",
       "max mean_per_class_accuracy  0.566988     0.859663  170"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 56.19 %, avg score: 57.17 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0186475</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0331867</td>\n",
       "<td>0.0331867</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0202202</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0027989</td>\n",
       "<td>0.0359856</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301056</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0535786</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0402157</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0179928</td>\n",
       "<td>0.0715714</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501011</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0891643</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002022</td>\n",
       "<td>0.9999867</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999969</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999985</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.1783287</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500786</td>\n",
       "<td>0.9996081</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999605</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.2670932</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001797</td>\n",
       "<td>0.9970159</td>\n",
       "<td>1.7717075</td>\n",
       "<td>1.7776907</td>\n",
       "<td>0.9955157</td>\n",
       "<td>0.9986017</td>\n",
       "<td>0.9988777</td>\n",
       "<td>0.9996204</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.3558577</td>\n",
       "<td>77.1707461</td>\n",
       "<td>77.7690719</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3001573</td>\n",
       "<td>0.9582869</td>\n",
       "<td>1.7037014</td>\n",
       "<td>1.7530461</td>\n",
       "<td>0.9573034</td>\n",
       "<td>0.9827594</td>\n",
       "<td>0.9850299</td>\n",
       "<td>0.9940043</td>\n",
       "<td>0.1703319</td>\n",
       "<td>0.5261895</td>\n",
       "<td>70.3701441</td>\n",
       "<td>75.3046087</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4001348</td>\n",
       "<td>0.8412151</td>\n",
       "<td>1.5557274</td>\n",
       "<td>1.7037441</td>\n",
       "<td>0.8741573</td>\n",
       "<td>0.9072918</td>\n",
       "<td>0.9573273</td>\n",
       "<td>0.9723383</td>\n",
       "<td>0.1555378</td>\n",
       "<td>0.6817273</td>\n",
       "<td>55.5727372</td>\n",
       "<td>70.3744106</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5001123</td>\n",
       "<td>0.6305704</td>\n",
       "<td>1.2957729</td>\n",
       "<td>1.6221865</td>\n",
       "<td>0.7280899</td>\n",
       "<td>0.7430516</td>\n",
       "<td>0.9115004</td>\n",
       "<td>0.9265016</td>\n",
       "<td>0.1295482</td>\n",
       "<td>0.8112755</td>\n",
       "<td>29.5772927</td>\n",
       "<td>62.2186525</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000899</td>\n",
       "<td>0.4112943</td>\n",
       "<td>0.9478339</td>\n",
       "<td>1.5098365</td>\n",
       "<td>0.5325843</td>\n",
       "<td>0.5155679</td>\n",
       "<td>0.8483714</td>\n",
       "<td>0.8580383</td>\n",
       "<td>0.0947621</td>\n",
       "<td>0.9060376</td>\n",
       "<td>-5.2166100</td>\n",
       "<td>50.9836500</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000674</td>\n",
       "<td>0.2441932</td>\n",
       "<td>0.5878970</td>\n",
       "<td>1.3781731</td>\n",
       "<td>0.3303371</td>\n",
       "<td>0.3246477</td>\n",
       "<td>0.7743902</td>\n",
       "<td>0.7818641</td>\n",
       "<td>0.0587765</td>\n",
       "<td>0.9648141</td>\n",
       "<td>-41.2103024</td>\n",
       "<td>37.8173121</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000449</td>\n",
       "<td>0.1109302</td>\n",
       "<td>0.2719523</td>\n",
       "<td>1.2399344</td>\n",
       "<td>0.1528090</td>\n",
       "<td>0.1726342</td>\n",
       "<td>0.6967144</td>\n",
       "<td>0.7057317</td>\n",
       "<td>0.0271891</td>\n",
       "<td>0.9920032</td>\n",
       "<td>-72.8047657</td>\n",
       "<td>23.9934355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000225</td>\n",
       "<td>0.0235088</td>\n",
       "<td>0.0759867</td>\n",
       "<td>1.1106391</td>\n",
       "<td>0.0426966</td>\n",
       "<td>0.0624814</td>\n",
       "<td>0.6240639</td>\n",
       "<td>0.6342773</td>\n",
       "<td>0.0075970</td>\n",
       "<td>0.9996002</td>\n",
       "<td>-92.4013316</td>\n",
       "<td>11.0639119</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000250</td>\n",
       "<td>0.0039993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0022472</td>\n",
       "<td>0.0079997</td>\n",
       "<td>0.5618962</td>\n",
       "<td>0.5716636</td>\n",
       "<td>0.0003998</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.6000701</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0186475                   1                  1.77969    1.77969            1                1           1                           1                   0.0331867       0.0331867                  77.9688   77.9688\n",
       "    2        0.0202202                   1                  1.77969    1.77969            1                1           1                           1                   0.00279888      0.0359856                  77.9688   77.9688\n",
       "    3        0.0301056                   1                  1.77969    1.77969            1                1           1                           1                   0.017593        0.0535786                  77.9688   77.9688\n",
       "    4        0.0402157                   1                  1.77969    1.77969            1                1           1                           1                   0.0179928       0.0715714                  77.9688   77.9688\n",
       "    5        0.0501011                   1                  1.77969    1.77969            1                1           1                           1                   0.017593        0.0891643                  77.9688   77.9688\n",
       "    6        0.100202                    0.999987           1.77969    1.77969            1                0.999997    1                           0.999998            0.0891643       0.178329                   77.9688   77.9688\n",
       "    7        0.150079                    0.999608           1.77969    1.77969            1                0.999884    1                           0.99996             0.0887645       0.267093                   77.9688   77.9688\n",
       "    8        0.20018                     0.997016           1.77171    1.77769            0.995516         0.998602    0.998878                    0.99962             0.0887645       0.355858                   77.1707   77.7691\n",
       "    9        0.300157                    0.958287           1.7037     1.75305            0.957303         0.982759    0.98503                     0.994004            0.170332        0.52619                    70.3701   75.3046\n",
       "    10       0.400135                    0.841215           1.55573    1.70374            0.874157         0.907292    0.957327                    0.972338            0.155538        0.681727                   55.5727   70.3744\n",
       "    11       0.500112                    0.63057            1.29577    1.62219            0.72809          0.743052    0.9115                      0.926502            0.129548        0.811275                   29.5773   62.2187\n",
       "    12       0.60009                     0.411294           0.947834   1.50984            0.532584         0.515568    0.848371                    0.858038            0.0947621       0.906038                   -5.21661  50.9836\n",
       "    13       0.700067                    0.244193           0.587897   1.37817            0.330337         0.324648    0.77439                     0.781864            0.0587765       0.964814                   -41.2103  37.8173\n",
       "    14       0.800045                    0.11093            0.271952   1.23993            0.152809         0.172634    0.696714                    0.705732            0.0271891       0.992003                   -72.8048  23.9934\n",
       "    15       0.900022                    0.0235088          0.0759867  1.11064            0.0426966        0.0624814   0.624064                    0.634277            0.00759696      0.9996                     -92.4013  11.0639\n",
       "    16       1                           2.49762e-05        0.0039993  1                  0.00224719       0.00799966  0.561896                    0.571664            0.00039984      1                          -99.6001  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def.model_performance(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1550560078082_1\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.07923591586779916\n",
      "RMSE: 0.28148874909629895\n",
      "LogLoss: 0.2515024423633179\n",
      "Mean Per-Class Error: 0.11118511506299722\n",
      "AUC: 0.9615873203700305\n",
      "pr_auc: 0.6868096836655864\n",
      "Gini: 0.923174640740061\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45265870981234596: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>3840.0</td>\n",
       "<td>661.0</td>\n",
       "<td>0.1469</td>\n",
       "<td> (661.0/4501.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>478.0</td>\n",
       "<td>5042.0</td>\n",
       "<td>0.0866</td>\n",
       "<td> (478.0/5520.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4318.0</td>\n",
       "<td>5703.0</td>\n",
       "<td>0.1137</td>\n",
       "<td> (1139.0/10021.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  ----------------\n",
       "NO     3840  661    0.1469   (661.0/4501.0)\n",
       "YES    478   5042   0.0866   (478.0/5520.0)\n",
       "Total  4318  5703   0.1137   (1139.0/10021.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4526587</td>\n",
       "<td>0.8985120</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2436426</td>\n",
       "<td>0.9301844</td>\n",
       "<td>279.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7338900</td>\n",
       "<td>0.9228737</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5199071</td>\n",
       "<td>0.8884343</td>\n",
       "<td>180.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999483</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0293821</td>\n",
       "<td>1.0</td>\n",
       "<td>377.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999483</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5199071</td>\n",
       "<td>0.7753334</td>\n",
       "<td>180.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5199071</td>\n",
       "<td>0.8876812</td>\n",
       "<td>180.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6120089</td>\n",
       "<td>0.8888149</td>\n",
       "<td>150.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.452659     0.898512  201\n",
       "max f2                       0.243643     0.930184  279\n",
       "max f0point5                 0.73389      0.922874  114\n",
       "max accuracy                 0.519907     0.888434  180\n",
       "max precision                0.999948     1         0\n",
       "max recall                   0.0293821    1         377\n",
       "max specificity              0.999948     1         0\n",
       "max absolute_mcc             0.519907     0.775333  180\n",
       "max min_per_class_accuracy   0.519907     0.887681  180\n",
       "max mean_per_class_accuracy  0.612009     0.888815  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 55.08 %, avg score: 56.61 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0186608</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0338768</td>\n",
       "<td>0.0338768</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0201577</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0027174</td>\n",
       "<td>0.0365942</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300369</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0179348</td>\n",
       "<td>0.0545290</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400160</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0181159</td>\n",
       "<td>0.0726449</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500948</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0182971</td>\n",
       "<td>0.0909420</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000898</td>\n",
       "<td>0.9999872</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999970</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999985</td>\n",
       "<td>0.0907609</td>\n",
       "<td>0.1817029</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500848</td>\n",
       "<td>0.9996836</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998938</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999636</td>\n",
       "<td>0.0907609</td>\n",
       "<td>0.2724638</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000798</td>\n",
       "<td>0.9973214</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.8153986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988263</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996794</td>\n",
       "<td>0.0907609</td>\n",
       "<td>0.3632246</td>\n",
       "<td>81.5398551</td>\n",
       "<td>81.5398551</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000699</td>\n",
       "<td>0.9663978</td>\n",
       "<td>1.8009044</td>\n",
       "<td>1.8105688</td>\n",
       "<td>0.9920160</td>\n",
       "<td>0.9859682</td>\n",
       "<td>0.9973395</td>\n",
       "<td>0.9951105</td>\n",
       "<td>0.1800725</td>\n",
       "<td>0.5432971</td>\n",
       "<td>80.0904351</td>\n",
       "<td>81.0568757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000599</td>\n",
       "<td>0.8513010</td>\n",
       "<td>1.6940096</td>\n",
       "<td>1.7814362</td>\n",
       "<td>0.9331337</td>\n",
       "<td>0.9187505</td>\n",
       "<td>0.9812921</td>\n",
       "<td>0.9760253</td>\n",
       "<td>0.1693841</td>\n",
       "<td>0.7126812</td>\n",
       "<td>69.4009626</td>\n",
       "<td>78.1436243</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000499</td>\n",
       "<td>0.6157410</td>\n",
       "<td>1.3606430</td>\n",
       "<td>1.6972944</td>\n",
       "<td>0.7495010</td>\n",
       "<td>0.7435451</td>\n",
       "<td>0.9349431</td>\n",
       "<td>0.9295385</td>\n",
       "<td>0.1360507</td>\n",
       "<td>0.8487319</td>\n",
       "<td>36.0643026</td>\n",
       "<td>69.7294394</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000399</td>\n",
       "<td>0.3906149</td>\n",
       "<td>0.8479107</td>\n",
       "<td>1.5557540</td>\n",
       "<td>0.4670659</td>\n",
       "<td>0.4957296</td>\n",
       "<td>0.8569766</td>\n",
       "<td>0.8572491</td>\n",
       "<td>0.0847826</td>\n",
       "<td>0.9335145</td>\n",
       "<td>-15.2089300</td>\n",
       "<td>55.5753988</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000299</td>\n",
       "<td>0.2188787</td>\n",
       "<td>0.4601909</td>\n",
       "<td>1.3992673</td>\n",
       "<td>0.2534930</td>\n",
       "<td>0.3039836</td>\n",
       "<td>0.7707769</td>\n",
       "<td>0.7782224</td>\n",
       "<td>0.0460145</td>\n",
       "<td>0.9795290</td>\n",
       "<td>-53.9809150</td>\n",
       "<td>39.9267279</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000200</td>\n",
       "<td>0.0938104</td>\n",
       "<td>0.1721186</td>\n",
       "<td>1.2458928</td>\n",
       "<td>0.0948104</td>\n",
       "<td>0.1508221</td>\n",
       "<td>0.6862916</td>\n",
       "<td>0.6998072</td>\n",
       "<td>0.0172101</td>\n",
       "<td>0.9967391</td>\n",
       "<td>-82.7881375</td>\n",
       "<td>24.5892831</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000100</td>\n",
       "<td>0.0225358</td>\n",
       "<td>0.0326120</td>\n",
       "<td>1.1110988</td>\n",
       "<td>0.0179641</td>\n",
       "<td>0.0537269</td>\n",
       "<td>0.6120412</td>\n",
       "<td>0.6280284</td>\n",
       "<td>0.0032609</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.7388050</td>\n",
       "<td>11.1098791</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000265</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0082448</td>\n",
       "<td>0.5508432</td>\n",
       "<td>0.5660562</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0186608                   1                  1.8154    1.8154             1                1           1                           1                   0.0338768       0.0338768                  81.5399   81.5399\n",
       "    2        0.0201577                   1                  1.8154    1.8154             1                1           1                           1                   0.00271739      0.0365942                  81.5399   81.5399\n",
       "    3        0.0300369                   1                  1.8154    1.8154             1                1           1                           1                   0.0179348       0.054529                   81.5399   81.5399\n",
       "    4        0.040016                    1                  1.8154    1.8154             1                1           1                           1                   0.0181159       0.0726449                  81.5399   81.5399\n",
       "    5        0.0500948                   1                  1.8154    1.8154             1                1           1                           1                   0.0182971       0.090942                   81.5399   81.5399\n",
       "    6        0.10009                     0.999987           1.8154    1.8154             1                0.999997    1                           0.999998            0.0907609       0.181703                   81.5399   81.5399\n",
       "    7        0.150085                    0.999684           1.8154    1.8154             1                0.999894    1                           0.999964            0.0907609       0.272464                   81.5399   81.5399\n",
       "    8        0.20008                     0.997321           1.8154    1.8154             1                0.998826    1                           0.999679            0.0907609       0.363225                   81.5399   81.5399\n",
       "    9        0.30007                     0.966398           1.8009    1.81057            0.992016         0.985968    0.99734                     0.995111            0.180072        0.543297                   80.0904   81.0569\n",
       "    10       0.40006                     0.851301           1.69401   1.78144            0.933134         0.91875     0.981292                    0.976025            0.169384        0.712681                   69.401    78.1436\n",
       "    11       0.50005                     0.615741           1.36064   1.69729            0.749501         0.743545    0.934943                    0.929539            0.136051        0.848732                   36.0643   69.7294\n",
       "    12       0.60004                     0.390615           0.847911  1.55575            0.467066         0.49573     0.856977                    0.857249            0.0847826       0.933514                   -15.2089  55.5754\n",
       "    13       0.70003                     0.218879           0.460191  1.39927            0.253493         0.303984    0.770777                    0.778222            0.0460145       0.979529                   -53.9809  39.9267\n",
       "    14       0.80002                     0.0938104          0.172119  1.24589            0.0948104        0.150822    0.686292                    0.699807            0.0172101       0.996739                   -82.7881  24.5893\n",
       "    15       0.90001                     0.0225358          0.032612  1.1111             0.0179641        0.0537269   0.612041                    0.628028            0.00326087      1                          -96.7388  11.1099\n",
       "    16       1                           2.64644e-05        0         1                  0                0.00824482  0.550843                    0.566056            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.1009114684352733\n",
      "RMSE: 0.31766565510812356\n",
      "LogLoss: 0.31792441900953383\n",
      "Mean Per-Class Error: 0.14440600651982494\n",
      "AUC: 0.9380406508146907\n",
      "pr_auc: 0.6714700309338802\n",
      "Gini: 0.8760813016293814\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3978705061270781: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1512.0</td>\n",
       "<td>421.0</td>\n",
       "<td>0.2178</td>\n",
       "<td> (421.0/1933.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>207.0</td>\n",
       "<td>2132.0</td>\n",
       "<td>0.0885</td>\n",
       "<td> (207.0/2339.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1719.0</td>\n",
       "<td>2553.0</td>\n",
       "<td>0.147</td>\n",
       "<td> (628.0/4272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1512  421    0.2178   (421.0/1933.0)\n",
       "YES    207   2132   0.0885   (207.0/2339.0)\n",
       "Total  1719  2553   0.147    (628.0/4272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3978705</td>\n",
       "<td>0.8716271</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1873418</td>\n",
       "<td>0.9162114</td>\n",
       "<td>303.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7019639</td>\n",
       "<td>0.8899423</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4844833</td>\n",
       "<td>0.8572097</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999611</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0299674</td>\n",
       "<td>1.0</td>\n",
       "<td>375.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999611</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4844833</td>\n",
       "<td>0.7116509</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5226163</td>\n",
       "<td>0.8520735</td>\n",
       "<td>184.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4844833</td>\n",
       "<td>0.8555940</td>\n",
       "<td>197.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.397871     0.871627  227\n",
       "max f2                       0.187342     0.916211  303\n",
       "max f0point5                 0.701964     0.889942  126\n",
       "max accuracy                 0.484483     0.85721   197\n",
       "max precision                0.999961     1         0\n",
       "max recall                   0.0299674    1         375\n",
       "max specificity              0.999961     1         0\n",
       "max absolute_mcc             0.484483     0.711651  197\n",
       "max min_per_class_accuracy   0.522616     0.852074  184\n",
       "max mean_per_class_accuracy  0.484483     0.855594  197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.75 %, avg score: 56.16 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0187266</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0342027</td>\n",
       "<td>0.0342027</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0201311</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025652</td>\n",
       "<td>0.0367678</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301966</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0183839</td>\n",
       "<td>0.0551518</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400281</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0179564</td>\n",
       "<td>0.0731082</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500936</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0183839</td>\n",
       "<td>0.0914921</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1001873</td>\n",
       "<td>0.9999913</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999981</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999991</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.1829842</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500468</td>\n",
       "<td>0.9996580</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999100</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999695</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.2740487</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001404</td>\n",
       "<td>0.9974304</td>\n",
       "<td>1.7922828</td>\n",
       "<td>1.8178769</td>\n",
       "<td>0.9813084</td>\n",
       "<td>0.9988493</td>\n",
       "<td>0.9953216</td>\n",
       "<td>0.9996891</td>\n",
       "<td>0.0897820</td>\n",
       "<td>0.3638307</td>\n",
       "<td>79.2282827</td>\n",
       "<td>81.7876885</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000936</td>\n",
       "<td>0.9591367</td>\n",
       "<td>1.7622615</td>\n",
       "<td>1.7993529</td>\n",
       "<td>0.9648712</td>\n",
       "<td>0.9839057</td>\n",
       "<td>0.9851794</td>\n",
       "<td>0.9944321</td>\n",
       "<td>0.1761437</td>\n",
       "<td>0.5399743</td>\n",
       "<td>76.2261540</td>\n",
       "<td>79.9352898</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000468</td>\n",
       "<td>0.8336227</td>\n",
       "<td>1.5355628</td>\n",
       "<td>1.7334440</td>\n",
       "<td>0.8407494</td>\n",
       "<td>0.9048262</td>\n",
       "<td>0.9490930</td>\n",
       "<td>0.9720437</td>\n",
       "<td>0.1534844</td>\n",
       "<td>0.6934587</td>\n",
       "<td>53.5562847</td>\n",
       "<td>73.3443973</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6013659</td>\n",
       "<td>1.2575361</td>\n",
       "<td>1.6383070</td>\n",
       "<td>0.6885246</td>\n",
       "<td>0.7234384</td>\n",
       "<td>0.8970037</td>\n",
       "<td>0.9223459</td>\n",
       "<td>0.1256947</td>\n",
       "<td>0.8191535</td>\n",
       "<td>25.7536148</td>\n",
       "<td>63.8306969</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999532</td>\n",
       "<td>0.3927567</td>\n",
       "<td>0.9324588</td>\n",
       "<td>1.5207115</td>\n",
       "<td>0.5105386</td>\n",
       "<td>0.4895549</td>\n",
       "<td>0.8326180</td>\n",
       "<td>0.8502422</td>\n",
       "<td>0.0932022</td>\n",
       "<td>0.9123557</td>\n",
       "<td>-6.7541224</td>\n",
       "<td>52.0711503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999064</td>\n",
       "<td>0.2169637</td>\n",
       "<td>0.5261121</td>\n",
       "<td>1.3786734</td>\n",
       "<td>0.2880562</td>\n",
       "<td>0.2978253</td>\n",
       "<td>0.7548495</td>\n",
       "<td>0.7713519</td>\n",
       "<td>0.0525866</td>\n",
       "<td>0.9649423</td>\n",
       "<td>-47.3887938</td>\n",
       "<td>37.8673389</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7998596</td>\n",
       "<td>0.0981866</td>\n",
       "<td>0.2651947</td>\n",
       "<td>1.2395293</td>\n",
       "<td>0.1451991</td>\n",
       "<td>0.1541919</td>\n",
       "<td>0.6786655</td>\n",
       "<td>0.6942295</td>\n",
       "<td>0.0265071</td>\n",
       "<td>0.9914493</td>\n",
       "<td>-73.4805302</td>\n",
       "<td>23.9529286</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8998127</td>\n",
       "<td>0.0222035</td>\n",
       "<td>0.0855467</td>\n",
       "<td>1.1113424</td>\n",
       "<td>0.0468384</td>\n",
       "<td>0.0550399</td>\n",
       "<td>0.6084807</td>\n",
       "<td>0.6232269</td>\n",
       "<td>0.0085507</td>\n",
       "<td>1.0</td>\n",
       "<td>-91.4453323</td>\n",
       "<td>11.1342352</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000225</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0081404</td>\n",
       "<td>0.5475187</td>\n",
       "<td>0.5616031</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0187266                   1                  1.82642    1.82642            1                1           1                           1                   0.0342027       0.0342027                  82.6422   82.6422\n",
       "    2        0.0201311                   1                  1.82642    1.82642            1                1           1                           1                   0.0025652       0.0367678                  82.6422   82.6422\n",
       "    3        0.0301966                   1                  1.82642    1.82642            1                1           1                           1                   0.0183839       0.0551518                  82.6422   82.6422\n",
       "    4        0.0400281                   1                  1.82642    1.82642            1                1           1                           1                   0.0179564       0.0731082                  82.6422   82.6422\n",
       "    5        0.0500936                   1                  1.82642    1.82642            1                1           1                           1                   0.0183839       0.0914921                  82.6422   82.6422\n",
       "    6        0.100187                    0.999991           1.82642    1.82642            1                0.999998    1                           0.999999            0.0914921       0.182984                   82.6422   82.6422\n",
       "    7        0.150047                    0.999658           1.82642    1.82642            1                0.99991     1                           0.999969            0.0910646       0.274049                   82.6422   82.6422\n",
       "    8        0.20014                     0.99743            1.79228    1.81788            0.981308         0.998849    0.995322                    0.999689            0.089782        0.363831                   79.2283   81.7877\n",
       "    9        0.300094                    0.959137           1.76226    1.79935            0.964871         0.983906    0.985179                    0.994432            0.176144        0.539974                   76.2262   79.9353\n",
       "    10       0.400047                    0.833623           1.53556    1.73344            0.840749         0.904826    0.949093                    0.972044            0.153484        0.693459                   53.5563   73.3444\n",
       "    11       0.5                         0.601366           1.25754    1.63831            0.688525         0.723438    0.897004                    0.922346            0.125695        0.819153                   25.7536   63.8307\n",
       "    12       0.599953                    0.392757           0.932459   1.52071            0.510539         0.489555    0.832618                    0.850242            0.0932022       0.912356                   -6.75412  52.0712\n",
       "    13       0.699906                    0.216964           0.526112   1.37867            0.288056         0.297825    0.754849                    0.771352            0.0525866       0.964942                   -47.3888  37.8673\n",
       "    14       0.79986                     0.0981866          0.265195   1.23953            0.145199         0.154192    0.678665                    0.694229            0.0265071       0.991449                   -73.4805  23.9529\n",
       "    15       0.899813                    0.0222035          0.0855467  1.11134            0.0468384        0.0550399   0.608481                    0.623227            0.00855066      1                          -91.4453  11.1342\n",
       "    16       1                           2.25107e-05        0          1                  0                0.00814044  0.547519                    0.561603            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-19 14:59:14</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-19 14:59:19</td>\n",
       "<td>17.165 sec</td>\n",
       "<td>495 obs/sec</td>\n",
       "<td>0.0620905</td>\n",
       "<td>1</td>\n",
       "<td>2189.0</td>\n",
       "<td>0.5231668</td>\n",
       "<td>0.7675992</td>\n",
       "<td>-0.1062528</td>\n",
       "<td>0.6812710</td>\n",
       "<td>0.7260124</td>\n",
       "<td>1.8153986</td>\n",
       "<td>0.3965672</td>\n",
       "<td>0.5257170</td>\n",
       "<td>0.7768440</td>\n",
       "<td>-0.1155895</td>\n",
       "<td>0.6705898</td>\n",
       "<td>0.7135377</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.4108146</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-19 15:01:17</td>\n",
       "<td> 2 min 11.686 sec</td>\n",
       "<td>1839 obs/sec</td>\n",
       "<td>5.7851936</td>\n",
       "<td>92</td>\n",
       "<td>203957.0</td>\n",
       "<td>0.3661516</td>\n",
       "<td>0.4085933</td>\n",
       "<td>0.4581290</td>\n",
       "<td>0.9262048</td>\n",
       "<td>0.8177236</td>\n",
       "<td>1.8153986</td>\n",
       "<td>0.1791238</td>\n",
       "<td>0.3815479</td>\n",
       "<td>0.4468314</td>\n",
       "<td>0.4123772</td>\n",
       "<td>0.9090576</td>\n",
       "<td>0.7988753</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.2059925</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-19 15:02:39</td>\n",
       "<td> 3 min 35.073 sec</td>\n",
       "<td>1841 obs/sec</td>\n",
       "<td>9.6386328</td>\n",
       "<td>153</td>\n",
       "<td>339810.0</td>\n",
       "<td>0.3582579</td>\n",
       "<td>0.3866126</td>\n",
       "<td>0.4812410</td>\n",
       "<td>0.9601621</td>\n",
       "<td>0.7515171</td>\n",
       "<td>1.8153986</td>\n",
       "<td>0.1146592</td>\n",
       "<td>0.3810737</td>\n",
       "<td>0.4508999</td>\n",
       "<td>0.4138371</td>\n",
       "<td>0.9372670</td>\n",
       "<td>0.7259284</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1507491</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-19 15:02:56</td>\n",
       "<td> 3 min 49.916 sec</td>\n",
       "<td>1846 obs/sec</td>\n",
       "<td>10.0220962</td>\n",
       "<td>159</td>\n",
       "<td>353329.0</td>\n",
       "<td>0.2814887</td>\n",
       "<td>0.2515024</td>\n",
       "<td>0.6797449</td>\n",
       "<td>0.9615873</td>\n",
       "<td>0.6868097</td>\n",
       "<td>1.8153986</td>\n",
       "<td>0.1136613</td>\n",
       "<td>0.3176657</td>\n",
       "<td>0.3179244</td>\n",
       "<td>0.5926751</td>\n",
       "<td>0.9380407</td>\n",
       "<td>0.6714700</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1470037</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs     iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  ---------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2019-02-19 14:59:14  0.000 sec                           0          0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2019-02-19 14:59:19  17.165 sec        495 obs/sec       0.0620905  1             2189       0.523167         0.767599            -0.106253      0.681271        0.726012           1.8154           0.396567                         0.525717           0.776844              -0.115589        0.67059           0.713538             1.82642            0.410815\n",
       "    2019-02-19 15:01:17  2 min 11.686 sec  1839 obs/sec      5.78519    92            203957     0.366152         0.408593            0.458129       0.926205        0.817724           1.8154           0.179124                         0.381548           0.446831              0.412377         0.909058          0.798875             1.82642            0.205993\n",
       "    2019-02-19 15:02:39  3 min 35.073 sec  1841 obs/sec      9.63863    153           339810     0.358258         0.386613            0.481241       0.960162        0.751517           1.8154           0.114659                         0.381074           0.4509                0.413837         0.937267          0.725928             1.82642            0.150749\n",
       "    2019-02-19 15:02:56  3 min 49.916 sec  1846 obs/sec      10.0221    159           353329     0.281489         0.251502            0.679745       0.961587        0.68681            1.8154           0.113661                         0.317666           0.317924              0.592675         0.938041          0.67147              1.82642            0.147004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ArrTime</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025012</td></tr>\n",
       "<tr><td>CRSArrTime</td>\n",
       "<td>0.8498962</td>\n",
       "<td>0.8498962</td>\n",
       "<td>0.0021258</td></tr>\n",
       "<tr><td>TailNum.NA</td>\n",
       "<td>0.7284701</td>\n",
       "<td>0.7284701</td>\n",
       "<td>0.0018221</td></tr>\n",
       "<tr><td>DepTime</td>\n",
       "<td>0.6060363</td>\n",
       "<td>0.6060363</td>\n",
       "<td>0.0015158</td></tr>\n",
       "<tr><td>CRSDepTime</td>\n",
       "<td>0.5962346</td>\n",
       "<td>0.5962346</td>\n",
       "<td>0.0014913</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>TailNum.N339UA</td>\n",
       "<td>0.0873564</td>\n",
       "<td>0.0873564</td>\n",
       "<td>0.0002185</td></tr>\n",
       "<tr><td>TailNum.N424UA</td>\n",
       "<td>0.0872493</td>\n",
       "<td>0.0872493</td>\n",
       "<td>0.0002182</td></tr>\n",
       "<tr><td>Dest.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Origin.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>UniqueCarrier.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ----------------------\n",
       "ArrTime                    1.0                    1.0                  0.002501221239846346\n",
       "CRSArrTime                 0.8498961925506592     0.8498961925506592   0.0021257784084722487\n",
       "TailNum.NA                 0.7284701466560364     0.7284701466560364   0.001822065003410061\n",
       "DepTime                    0.6060363054275513     0.6060363054275513   0.0015158308792533987\n",
       "CRSDepTime                 0.5962346196174622     0.5962346196174622   0.0014913146945189032\n",
       "---                        ---                    ---                  ---\n",
       "TailNum.N339UA             0.08735638856887817    0.08735638856887817  0.00021849765452474864\n",
       "TailNum.N424UA             0.08724933862686157    0.08724933862686157  0.0002182298989360524\n",
       "Dest.missing(NA)           0.0                    0.0                  0.0\n",
       "Origin.missing(NA)         0.0                    0.0                  0.0\n",
       "UniqueCarrier.missing(NA)  0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_def.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Idea : will more effort help ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |███████"
     ]
    }
   ],
   "source": [
    "m_200_epochs = H2ODeepLearningEstimator(epochs = 200, stopping_rounds = 5,\n",
    "                                        stopping_tolerance = 0,\n",
    "                                        stopping_metric = \"logloss \"\n",
    "                                       )\n",
    "%time m_200_epochs.train(xAll,y,train,validation_frame = valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200_epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning idea : does it need another layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200 = H2ODeepLearningEstimator(epochs = 200,\n",
    "                                         #same early stopping\n",
    "                                         hidden = [200,200,200]\n",
    "                                        )\n",
    "%time m_200x200x200.train(xAll, y, train , validation_frame =valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_200x200x200.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_400x400 = H2ODeepLearningEstimator(epochs = 200,\n",
    "                                         #same early stopping\n",
    "                                         hidden = [400,400]\n",
    "                                        )\n",
    "%time m_400x400.train(xAll, y, train , validation_frame =valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Machine_Learning)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
